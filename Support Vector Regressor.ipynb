{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a0c8aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from impyute.imputation.cs import mice, fast_knn\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, classification_report, confusion_matrix\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from boruta import BorutaPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a59ec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp_data_treatment(dataset, category='numeric'):\n",
    "    if category == 'binary':\n",
    "        for column in ['Mes', 'Hora Medicao']:\n",
    "            date = dataset[column]\n",
    "            _max = date.max()\n",
    "            i = 0\n",
    "            while 2**i < _max:\n",
    "                i += 1\n",
    "            binary_rep = [np.binary_repr(z,width=i) for z in date.astype('int')]\n",
    "            d = []\n",
    "            for k in range(i):\n",
    "                d.append(np.array([int(v) for s in binary_rep for v in s[k]]))\n",
    "            t = np.vstack((d)).T\n",
    "            if column == 'Mes':\n",
    "                df_mes = pd.DataFrame(t, columns= [f'Mes_Bit_{ind}' for ind in range(i)])\n",
    "            else:\n",
    "                df_hora = pd.DataFrame(t, columns= [f'Hora_Bit_{ind}' for ind in range(i)])\n",
    "\n",
    "    elif category == '1ofN':\n",
    "        for column in ['Mes','Hora Medicao']:\n",
    "            one_hot = pd.get_dummies(dataset[column])\n",
    "            listoflists = one_hot.values.tolist()\n",
    "            new_list = []\n",
    "            for lists in listoflists:\n",
    "                new_list.append(''.join(map(str, lists)))\n",
    "            d = []\n",
    "            if column == 'Mes':\n",
    "                for k in range(12):\n",
    "                        d.append(np.array([int(v) for s in new_list for v in s[k]]))\n",
    "                t = np.vstack((d)).T\n",
    "                df_mes = pd.DataFrame(t, columns= ['Jan', 'Fev', 'Mar','Abr','Mai', 'Jun', 'Jul', 'Ago', 'Set', 'Out', 'Nov', 'Dez'])\n",
    "            if column == 'Hora Medicao':\n",
    "                for k in range(24):\n",
    "                        d.append(np.array([int(v) for s in new_list for v in s[k]]))\n",
    "                t = np.vstack((d)).T\n",
    "                df_hora = pd.DataFrame(t, columns= [f'{ind} h' for ind in range(24)])\n",
    "            if column == 'Dia':\n",
    "                for k in range(24):\n",
    "                        d.append(np.array([int(v) for s in new_list for v in s[k]]))\n",
    "                t = np.vstack((d)).T\n",
    "                df_hora = pd.DataFrame(t, columns= [f'{ind} h' for ind in range(24)])\n",
    "    \n",
    "    elif category == 'numeric':\n",
    "        for column in ['Dia', 'Mes','Hora Medicao']:\n",
    "            _values = dataset[column].values\n",
    "            _max = dataset[column].max()\n",
    "            \n",
    "            _array = np.array([float(i/_max) for i in _values])\n",
    "            if column == 'Mes':\n",
    "                df_mes = pd.DataFrame(_array, columns= ['Mes'])\n",
    "            else:\n",
    "                df_hora = pd.DataFrame(_array, columns= ['Horas'])\n",
    "    else:\n",
    "        print('Invalid Category, please select another one...')\n",
    "\n",
    "    return df_mes, df_hora    \n",
    "\n",
    "\n",
    "def preparing_data(dataset, features = [], lag = 24, normalize = 'minmax', category = 'binary', onlyHour = False, onlyMonth = False):\n",
    "    _max = dataset.iloc[:,-1:].max().values\n",
    "    _min = dataset.iloc[:,-1:].min().values\n",
    "    _med = dataset.iloc[:,-1:].mean().values\n",
    "    _std = dataset.iloc[:,-1:].std().values\n",
    "    if normalize == 'minmax':\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset_norm = scaler.fit_transform(dataset.drop([i for i in dataset.columns if i in ['Dia', 'Mes', 'Ano', 'Hora Medicao']],axis=1))\n",
    "        dataset_norm = pd.DataFrame(dataset_norm, \n",
    "                                   columns = dataset.drop([i for i in dataset.columns if i in ['Dia', 'Mes', 'Ano', 'Hora Medicao']],axis=1).columns)\n",
    "    elif normalize == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "        dataset_norm = scaler.fit_transform(dataset.drop([i for i in dataset.columns if i in ['Dia', 'Mes', 'Ano', 'Hora Medicao']],axis=1))\n",
    "        dataset_norm = pd.DataFrame(dataset_norm, \n",
    "                                    columns = dataset.drop([i for i in dataset.columns if i in ['Dia', 'Mes', 'Ano', 'Hora Medicao']],axis=1).columns)\n",
    "    else:\n",
    "        print('Invalid Category, please select another one...')\n",
    "     \n",
    "    X, Y = look_back_function(dataset_norm['VENTO, VELOCIDADE HORARIA(m/s)'],lag)\n",
    "    trend = pd.DataFrame(X.iloc[:, -1] - X.iloc[:, -2], columns = ['Trend'])\n",
    "    X = pd.concat([trend, X], axis = 1)\n",
    "    mes, hora = timestamp_data_treatment(dataset, category)\n",
    "    \n",
    "    if len(features):\n",
    "        for feature in features:\n",
    "            if feature in dataset_norm.drop([i for i in dataset_norm.columns if i in ['Dia', 'Mes', 'Ano', 'Hora Medicao']], axis=1).columns:\n",
    "                X = pd.concat([dataset_norm[feature][lag:-1].reset_index(drop=True), X], axis=1)\n",
    "        \n",
    "    if onlyMonth:\n",
    "        _input = pd.concat([mes[lag:-1].reset_index(drop=True), X], axis=1)\n",
    "        \n",
    "    elif onlyHour:\n",
    "        _input = pd.concat([hora[lag:-1].reset_index(drop=True), X], axis=1)\n",
    "        \n",
    "    else:\n",
    "        _input = pd.concat([mes[lag:-1].reset_index(drop=True), hora[lag:-1].reset_index(drop=True), X], axis=1)\n",
    "        \n",
    "    return _input, Y,_max, _min, _med, _std\n",
    "        \n",
    "\n",
    "def look_back_function (dataset, look_back=24):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back])\n",
    "    X = pd.DataFrame(np.array(dataX), columns = [f'X(t-{ind})' for ind in reversed(range(look_back))])\n",
    "    Y = pd.DataFrame(np.array(dataY), columns=['Output'])\n",
    "    return X, Y\n",
    "\n",
    "def multistep_prediction(model, Input, lag):\n",
    "    other_features = Input.iloc[:, :(Input.shape[1]-lag)]\n",
    "    other_features_array = other_features.values\n",
    "\n",
    "    wind_feature = Input.iloc[:,-lag:]\n",
    "    wind_feature_array = wind_feature.values\n",
    "\n",
    "    for i in range(len(wind_feature_array)):\n",
    "        if i==0:\n",
    "            x_multistep = np.concatenate((other_features_array[i],wind_feature_array[i]))\n",
    "            _y_hat = model.predict(x_multistep.reshape(1,-1))\n",
    "            predict_array = np.array(_y_hat)\n",
    "        else:\n",
    "            if i < lag:\n",
    "                wind_array_copy =  wind_feature_array[i, :]\n",
    "                wind_array_copy = wind_array_copy[:-predict_array.shape[0]]\n",
    "                data_array_with_prediction = np.insert(wind_array_copy,wind_array_copy.size,predict_array)\n",
    "            else:\n",
    "                data_array_with_prediction = predict_array[-lag:]\n",
    "            x_multistep = np.concatenate((other_features_array[i],data_array_with_prediction))\n",
    "            _y_hat = model.predict(x_multistep.reshape(1,-1))\n",
    "            predict_array = np.append(predict_array, _y_hat)\n",
    "    predict_data = pd.DataFrame(predict_array, columns=['Predictions'])\n",
    "    return predict_data\n",
    "\n",
    "def mask_classification(raw_data):\n",
    "    classification_list = np.array([])\n",
    "    for idx, x in raw_data.iterrows():\n",
    "        if 0 <= x.values <= 4:\n",
    "            classification_list = np.append(classification_list, 1)\n",
    "        elif 4 < x.values <= 10:\n",
    "            classification_list = np.append(classification_list, 2)\n",
    "        elif 10 < x.values <= 15:\n",
    "            classification_list = np.append(classification_list, 3)\n",
    "        elif 15 < x.values <= 25:\n",
    "            classification_list = np.append(classification_list, 4)\n",
    "        else:\n",
    "            classification_list = np.append(classification_list, 5)\n",
    "    return classification_list\n",
    "\n",
    "def MAPE(testY, testPredict):\n",
    "    soma, cont = 0, 0\n",
    "    for idx, value in testY.iterrows():\n",
    "        if abs(value.values) >= 0.01:\n",
    "            erro = abs((value - testPredict.values[idx])/value)\n",
    "            soma += erro\n",
    "            cont += 1\n",
    "    mape = (soma/cont)*100\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4373ce85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_micetreated = pd.read_csv('Treino_Arraial_do_Cabo_MICE.csv', sep = ';')\n",
    "df_test_micetreated = pd.read_csv('Teste_Arraial_do_Cabo_MICE.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c664949",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_train_micetreated, df_test_micetreated])\n",
    "df = df.drop([i for i in df.columns if i in \n",
    "              ['Dia', 'Mes', 'Ano', 'Hora Medicao', 'TEMPERATURA DA CPU DA ESTACAO(°C)', 'TENSAO DA BATERIA DA ESTACAO(V)']],axis=1)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df_norm = scaler.fit_transform(df)\n",
    "df_norm = pd.DataFrame(df_norm, columns = df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb21a7d",
   "metadata": {},
   "source": [
    "**Seleção de Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0a6fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backward Elimination\n",
    "_x = df_norm.drop([i for i in df_norm.columns if i in ['VENTO, VELOCIDADE HORARIA(m/s)']],axis=1)\n",
    "_y = df_norm[\"VENTO, VELOCIDADE HORARIA(m/s)\"]\n",
    "cols = list(_x.columns)\n",
    "pmax = 1\n",
    "while (len(cols)>0):\n",
    "    p= []\n",
    "    X_1 = _x[cols]\n",
    "    X_1 = sm.add_constant(X_1)\n",
    "    model = sm.OLS(_y,X_1).fit()\n",
    "    p = pd.Series(model.pvalues.values[1:],index = cols)      \n",
    "    pmax = max(p)\n",
    "    feature_with_p_max = p.idxmax()\n",
    "    if(pmax>0.05):\n",
    "        cols.remove(feature_with_p_max)\n",
    "    else:\n",
    "        break\n",
    "selected_features_BE = cols\n",
    "print(selected_features_BE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a763c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFE\n",
    "nof_list=np.arange(1,df_norm.shape[1])            \n",
    "high_score=0\n",
    "\n",
    "nof=0           \n",
    "score_list =[]\n",
    "for n in range(len(nof_list)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(_x,_y, test_size = 0.3, random_state = 0)\n",
    "    model = LinearRegression()\n",
    "    rfe = RFE(model,nof_list[n])\n",
    "    X_train_rfe = rfe.fit_transform(X_train,y_train)\n",
    "    X_test_rfe = rfe.transform(X_test)\n",
    "    model.fit(X_train_rfe,y_train)\n",
    "    score = model.score(X_test_rfe,y_test)\n",
    "    score_list.append(score)\n",
    "    if(score>high_score):\n",
    "        high_score = score\n",
    "        nof = nof_list[n]\n",
    "print(\"Optimum number of features: %d\" %nof)\n",
    "print(\"Score with %d features: %f\" % (nof, high_score))\n",
    "cols = list(_x.columns)\n",
    "model = LinearRegression()\n",
    "\n",
    "#Initializing RFE model\n",
    "rfe = RFE(model, nof)\n",
    "\n",
    "#Transforming data using RFE\n",
    "X_rfe = rfe.fit_transform(_x,_y)\n",
    "\n",
    "#Fitting the data to model\n",
    "model.fit(X_rfe,_y)              \n",
    "temp = pd.Series(rfe.support_,index = cols)\n",
    "selected_features_rfe = temp[temp==True].index\n",
    "print(selected_features_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d35e9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EMbedded Method\n",
    "reg = LassoCV()\n",
    "reg.fit(_x, _y)\n",
    "print(\"Best alpha using built-in LassoCV: %f\" % reg.alpha_)\n",
    "print(\"Best score using built-in LassoCV: %f\" %reg.score(_x, _y))\n",
    "coef = pd.Series(reg.coef_, index = _x.columns)\n",
    "\n",
    "list_embedded = []\n",
    "for ind, value in coef.iteritems():\n",
    "    if value != 0:\n",
    "        list_embedded.append(ind)\n",
    "print(list_embedded)\n",
    "\n",
    "print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")\n",
    "\n",
    "imp_coef = coef.sort_values()\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Feature importance using Lasso Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b519cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor(max_depth = 5, random_state = 42)\n",
    "\n",
    "boruta_feature_selector = BorutaPy(forest, n_estimators='auto', verbose=0, random_state=4242, max_iter = 100, perc = 75)\n",
    "boruta_feature_selector.fit(np.array(_x), np.array(_y))\n",
    "\n",
    "final_features = list()\n",
    "indexes = np.where(boruta_feature_selector.support_ == True)\n",
    "for x in np.nditer(indexes):\n",
    "    final_features.append(df.columns[x])\n",
    "\n",
    "print(final_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0e13bc",
   "metadata": {},
   "source": [
    "**Interseção das Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cb0204",
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_elimination_list = set(selected_features_BE)\n",
    "RFE_list = set(selected_features_rfe)\n",
    "embedded_method_list = set(list_embedded)\n",
    "boruta_method_list = set(final_features)\n",
    "\n",
    "BE_RFE_List = backward_elimination_list.intersection(RFE_list)\n",
    "EM_BE_RFE_List = BE_RFE_List.intersection(embedded_method_list)\n",
    "final_feature_list = list(EM_BE_RFE_List.intersection(boruta_method_list))\n",
    "\n",
    "print(final_feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7eb852",
   "metadata": {},
   "source": [
    "**Previsão Horizonte de 1 dia**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce348f7",
   "metadata": {},
   "source": [
    "**Seleção de hiper-parâmetros com algoritmos genéticos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48007cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\diego\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\deap\\creator.py:138: RuntimeWarning: A class named 'FitnessMin' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "c:\\users\\diego\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\deap\\creator.py:138: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Lag: 12\n",
      "Train_Norm: minmax\n",
      "Train_Category: 1ofN\n",
      "Train_Hour: True\n",
      "Train_Month: False\n",
      "Test_Lag: 12\n",
      "Test_Norm: minmax\n",
      "Test_Category: 1ofN\n",
      "Test_Hour: True\n",
      "Test_Month: False\n",
      "kernel: rbf\n",
      "C: 28.945503351078816\n",
      "epsilon: 0.0026106660319077115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\diego\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from deap import base, creator, tools, algorithms\n",
    "import random\n",
    "\n",
    "def mutate(individual):\n",
    "    \n",
    "    gene = random.randint(0,7) #select which parameter to mutate\n",
    "    if gene == 0:\n",
    "        if individual[0] == 3:\n",
    "            individual[0] = random.choice([6, 12, 24])\n",
    "        elif individual[0] == 6:\n",
    "            individual[0] = random.choice([3, 12, 24])\n",
    "        elif individual[0] == 12:\n",
    "            individual[0] = random.choice([3, 6, 24])\n",
    "        else:\n",
    "            individual[0] = random.choice([3, 6, 12])\n",
    "    elif gene == 1:\n",
    "        if individual[1] == 'minmax':\n",
    "            individual[1] = 'standard'\n",
    "        else:\n",
    "            individual[1] = 'minmax'\n",
    "    elif gene == 2:\n",
    "        if individual[2] == 'numeric':\n",
    "            individual[2] = random.choice(['1ofN', 'binary'])\n",
    "        elif individual[2] == '1ofN':\n",
    "            individual[2] = random.choice(['numeric', 'binary'])\n",
    "        else:\n",
    "            individual[2] = random.choice(['numeric', '1ofN'])\n",
    "        \n",
    "    elif gene == 3:\n",
    "        if individual[3] == True:\n",
    "            individual[3] = False\n",
    "        else:\n",
    "            individual[3] = True\n",
    "\n",
    "    elif gene == 4:\n",
    "        if individual[4] == True:\n",
    "            individual[4] = False\n",
    "        else:\n",
    "            individual[4] = True\n",
    "    if gene == 5:\n",
    "        if individual[5] == 'linear':\n",
    "            individual[5] = random.choice(['poly', 'rbf', 'sigmoid'])\n",
    "        elif individual[5] == 'poly':\n",
    "            individual[5] = random.choice(['linear', 'rbf', 'sigmoid'])\n",
    "        elif individual[5] == 'rbf':\n",
    "            individual[5] = random.choice(['linear', 'poly', 'sigmoid'])\n",
    "        else:\n",
    "            individual[5] = random.choice(['linear', 'poly', 'rbf'])\n",
    "        \n",
    "    elif gene == 6:\n",
    "        individual[6] = random.uniform(lower_C, upper_C)\n",
    "            \n",
    "    elif gene == 7:\n",
    "        individual[7] = random.uniform(lower_epsilon, upper_epsilon)\n",
    "        \n",
    "    return individual,\n",
    "\n",
    "\n",
    "def evaluate(individual):\n",
    "    '''\n",
    "    build and test a model based on the parameters in an individual and return\n",
    "    the AUROC value\n",
    "    '''\n",
    "    # extract the values of the parameters from the individual chromosome\n",
    "    _lag = individual[0]\n",
    "    _normalize = individual[1]\n",
    "    _category = individual[2]\n",
    "    _month = individual[3]\n",
    "    _hour = individual[4]\n",
    "    _kernel = individual[5]\n",
    "    _C = individual[6]\n",
    "    _epsilon = individual[7]\n",
    "    \n",
    "    # build the model\n",
    "    print(f'Train_Lag: {_lag}')\n",
    "    print(f'Train_Norm: {_normalize}')\n",
    "    print(f'Train_Category: {_category}')\n",
    "    print(f'Train_Hour: {_hour}')\n",
    "    print(f'Train_Month: {_month}')\n",
    "    X_train, Y_train,_maxtrain, _mintrain, _meantrain, _stdtrain = preparing_data(df_train_micetreated, features = final_feature_list, lag = _lag, normalize = _normalize, category = _category, onlyHour = _hour, onlyMonth = _month)\n",
    "    print(f'Test_Lag: {_lag}')\n",
    "    print(f'Test_Norm: {_normalize}')\n",
    "    print(f'Test_Category: {_category}')\n",
    "    print(f'Test_Hour: {_hour}')\n",
    "    print(f'Test_Month: {_month}')\n",
    "    X_test, Y_test,_maxtest, _mintest, _meantest, _stdtest = preparing_data(df_test_micetreated, features = final_feature_list,lag = _lag, normalize = _normalize, category = _category, onlyHour = _hour, onlyMonth = _month)\n",
    "    \n",
    "    \n",
    "    print(f'kernel: {_kernel}')\n",
    "    print(f'C: {_C}')\n",
    "    print(f'epsilon: {_epsilon}')\n",
    "    \n",
    "    regressor = SVR(kernel=_kernel, \n",
    "                    C=_C, \n",
    "                    epsilon=_epsilon)\n",
    "    regressor.fit(X_train, Y_train)\n",
    "    \n",
    "    testpredictSVR = multistep_prediction(regressor, X_test[-24:], _lag)\n",
    "\n",
    "    orig_y_eval_test = Y_test[-24:]*(_maxtest - _mintest) + _mintest\n",
    "    orig_y_hat_test_svr = testpredictSVR*(_maxtest - _mintest) + _mintest\n",
    "\n",
    "    RMSE_test_svr = (mean_squared_error(orig_y_eval_test, orig_y_hat_test_svr))**0.5\n",
    "    \n",
    "\n",
    "    print(f'RMSE: {RMSE_test_svr}')\n",
    "    print('------'*20)\n",
    "    return RMSE_test_svr,\n",
    "\n",
    "\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,)) # Maximise the fitness function value\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# Possible parameter values\n",
    "lag_option = [3, 6, 12, 24]\n",
    "norm = ['minmax', 'standard']\n",
    "cat = ['numeric', '1ofN', 'binary']\n",
    "hour = [True, False]\n",
    "month = [True, False]\n",
    "list_kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "lower_C, upper_C = 0.1, 50\n",
    "lower_epsilon, upper_epsilon = 0.001,1 \n",
    "\n",
    "N_CYCLES = 1\n",
    "toolbox.register(\"attr_lag\", random.choice, lag_option)\n",
    "toolbox.register(\"attr_normalization\", random.choice, norm)\n",
    "toolbox.register(\"attr_category\", random.choice, cat)\n",
    "toolbox.register(\"attr_hour\", random.choice, hour)\n",
    "toolbox.register(\"attr_month\", random.choice, month)\n",
    "toolbox.register(\"attr_kernel\", random.choice, list_kernel)\n",
    "toolbox.register(\"attr_C\", random.uniform, lower_C, upper_C)\n",
    "toolbox.register(\"attr_epochs\", random.uniform, lower_epsilon, upper_epsilon)\n",
    "\n",
    "toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
    "                 (toolbox.attr_lag,toolbox.attr_normalization, toolbox.attr_category,\n",
    "                  toolbox.attr_hour,toolbox.attr_month,toolbox.attr_kernel,toolbox.attr_C, \n",
    "                  toolbox.attr_epochs), n=N_CYCLES)\n",
    "\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "\n",
    "toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "toolbox.register(\"mutate\",mutate)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=2)\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "\n",
    "population_size = 4\n",
    "crossover_probability = 0.75\n",
    "mutation_probability = 0.05\n",
    "number_of_generations = 50\n",
    "\n",
    "pop = toolbox.population(n=population_size)\n",
    "hof = tools.HallOfFame(3)\n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register(\"avg\", np.mean)\n",
    "stats.register(\"std\", np.std)\n",
    "stats.register(\"min\", np.min)\n",
    "stats.register(\"max\", np.max)\n",
    "pop, log = algorithms.eaSimple(pop, toolbox, cxpb=crossover_probability, stats = stats, \n",
    "                               mutpb = mutation_probability, ngen=number_of_generations, halloffame=hof, \n",
    "                               verbose=True) \n",
    "\n",
    "svr_best_parameters_1 = hof[0] # save the optimal set of parameters\n",
    "svr_best_parameters_2 = hof[1]\n",
    "svr_best_parameters_3 = hof[2]\n",
    "print(svr_best_parameters_1)\n",
    "print(svr_best_parameters_2)\n",
    "print(svr_best_parameters_3)\n",
    "\n",
    "gen = log.select(\"gen\")\n",
    "max_ = log.select(\"max\")\n",
    "avg = log.select(\"avg\")\n",
    "min_ = log.select(\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbb82e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "evolution = pd.DataFrame({'Generation': gen,\n",
    "                         'Max RMSE': max_,\n",
    "                          'Average':avg,\n",
    "                         'Min RMSE': min_})\n",
    "\n",
    "plt.title('Parameter Optimisation')\n",
    "plt.plot(evolution['Generation'], evolution['Min AUROC'], 'b', color = 'C1',\n",
    "         label = 'Min')\n",
    "plt.plot(evolution['Generation'], evolution['Average'], 'b', color = 'C2',\n",
    "         label = 'Average')\n",
    "plt.plot(evolution['Generation'], evolution['Max RMSE'], 'b', color = 'C3',\n",
    "         label= 'Max')\n",
    "\n",
    "\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.ylabel('RMSE')\n",
    "plt.xlabel('Generation')\n",
    "plt.xticks([0,5,10,15,20, 25, 30, 35, 40 ,45, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e461cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train,_maxtrain, _mintrain, _meantrain, _stdtrain = preparing_data(df_train_micetreated, features= final_feature_list, lag = 24, normalize = 'minmax', category = '1ofN', onlyHour = , onlyMonth = )\n",
    "X_test, Y_test,_maxtest, _mintest, _meantest, _stdtest = preparing_data(df_test_micetreated, features= final_feature_list, lag = 24, normalize = 'minmax', category = '1ofN', onlyHour = , onlyMonth = )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c1e7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = SVR(kernel = svr_best_parameters_1[0], C=svr_best_parameters_1[1], epsilon=svr_best_parameters_1[2])\n",
    "regressor.fit(X_train, Y_train)\n",
    "\n",
    "testpredictSVR = multistep_prediction(regressor, X_test, 24)\n",
    "\n",
    "orig_y_eval_test = Y_test*(_maxtest - _mintest) + _mintest\n",
    "orig_y_hat_test_svr = testpredictSVR*(_maxtest - _mintest) + _mintest\n",
    "\n",
    "RMSE_test_svr = (mean_squared_error(orig_y_eval_test, orig_y_hat_test_svr))**0.5\n",
    "mape_svr = MAPE(orig_y_eval_test, orig_y_hat_test_svr)\n",
    "\n",
    "print(f'RMSE: {RMSE_test_svr}')\n",
    "print(f'MAPE: {mape_svr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41985ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_real_day = mask_classification(orig_y_eval_test_day)\n",
    "classification_forecasting_svr_day = mask_classification(orig_y_hat_test_svr_day)\n",
    "\n",
    "print(confusion_matrix(classification_real_day, classification_forecasting_svr_day))\n",
    "cm_svr_day = confusion_matrix(classification_real_day, classification_forecasting_svr_day)\n",
    "\n",
    "cmn_day = cm_svr_day.astype('float') / cm_svr_day.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cmn_day,annot=True)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d67bb9c",
   "metadata": {},
   "source": [
    "**Previsão Horizonte de 1 dia**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43e189e",
   "metadata": {},
   "source": [
    "**Seleção de hiper-parâmetros com algoritmos genéticos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37da6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import base, creator, tools, algorithms\n",
    "import random\n",
    "\n",
    "def mutate(individual):\n",
    "    \n",
    "    gene = random.randint(0,7) #select which parameter to mutate\n",
    "    if gene == 0:\n",
    "        if individual[0] == 3:\n",
    "            individual[0] = random.choice([6, 12, 24])\n",
    "        elif individual[0] == 6:\n",
    "            individual[0] = random.choice([3, 12, 24])\n",
    "        elif individual[0] == 12:\n",
    "            individual[0] = random.choice([3, 6, 24])\n",
    "        else:\n",
    "            individual[0] = random.choice([3, 6, 12])\n",
    "    elif gene == 1:\n",
    "        if individual[1] == 'minmax':\n",
    "            individual[1] = 'standard'\n",
    "        else:\n",
    "            individual[1] = 'minmax'\n",
    "    elif gene == 2:\n",
    "        if individual[2] == 'numeric':\n",
    "            individual[2] = random.choice(['1ofN', 'binary'])\n",
    "        elif individual[2] == '1ofN':\n",
    "            individual[2] = random.choice(['numeric', 'binary'])\n",
    "        else:\n",
    "            individual[2] = random.choice(['numeric', '1ofN'])\n",
    "        \n",
    "    elif gene == 3:\n",
    "        if individual[3] == True:\n",
    "            individual[3] = False\n",
    "        else:\n",
    "            individual[3] = True\n",
    "\n",
    "    elif gene == 4:\n",
    "        if individual[4] == True:\n",
    "            individual[4] = False\n",
    "        else:\n",
    "            individual[4] = True\n",
    "    if gene == 5:\n",
    "        if individual[5] == 'linear':\n",
    "            individual[5] = random.choice(['poly', 'rbf', 'sigmoid'])\n",
    "        elif individual[5] == 'poly':\n",
    "            individual[5] = random.choice(['linear', 'rbf', 'sigmoid'])\n",
    "        elif individual[5] == 'rbf':\n",
    "            individual[5] = random.choice(['linear', 'poly', 'sigmoid'])\n",
    "        else:\n",
    "            individual[5] = random.choice(['linear', 'poly', 'rbf'])\n",
    "        \n",
    "    elif gene == 6:\n",
    "        individual[6] = random.uniform(lower_C, upper_C)\n",
    "            \n",
    "    elif gene == 7:\n",
    "        individual[7] = random.uniform(lower_epsilon, upper_epsilon)\n",
    "        \n",
    "    return individual,\n",
    "\n",
    "\n",
    "def evaluate(individual):\n",
    "    '''\n",
    "    build and test a model based on the parameters in an individual and return\n",
    "    the AUROC value\n",
    "    '''\n",
    "    # extract the values of the parameters from the individual chromosome\n",
    "    _lag = individual[0]\n",
    "    _normalize = individual[1]\n",
    "    _category = individual[2]\n",
    "    _month = individual[3]\n",
    "    _hour = individual[4]\n",
    "    _kernel = individual[5]\n",
    "    _C = individual[6]\n",
    "    _epsilon = individual[7]\n",
    "    \n",
    "    # build the model\n",
    "    print(f'Train_Lag: {_lag}')\n",
    "    print(f'Train_Norm: {_normalize}')\n",
    "    print(f'Train_Category: {_category}')\n",
    "    print(f'Train_Hour: {_hour}')\n",
    "    print(f'Train_Month: {_month}')\n",
    "    X_train, Y_train,_maxtrain, _mintrain, _meantrain, _stdtrain = preparing_data(df_train_micetreated, features = final_feature_list, lag = _lag, normalize = _normalize, category = _category, onlyHour = _hour, onlyMonth = _month)\n",
    "    print(f'Test_Lag: {_lag}')\n",
    "    print(f'Test_Norm: {_normalize}')\n",
    "    print(f'Test_Category: {_category}')\n",
    "    print(f'Test_Hour: {_hour}')\n",
    "    print(f'Test_Month: {_month}')\n",
    "    X_test, Y_test,_maxtest, _mintest, _meantest, _stdtest = preparing_data(df_test_micetreated, features = final_feature_list,lag = _lag, normalize = _normalize, category = _category, onlyHour = _hour, onlyMonth = _month)\n",
    "    \n",
    "    \n",
    "    print(f'kernel: {_kernel}')\n",
    "    print(f'C: {_C}')\n",
    "    print(f'epsilon: {_epsilon}')\n",
    "    \n",
    "    regressor = SVR(kernel=_kernel, \n",
    "                    C=_C, \n",
    "                    epsilon=_epsilon)\n",
    "    regressor.fit(X_train, Y_train)\n",
    "    \n",
    "    testpredictSVR = multistep_prediction(regressor, X_test[-168:], _lag)\n",
    "\n",
    "    orig_y_eval_test = Y_test[-168:]*(_maxtest - _mintest) + _mintest\n",
    "    orig_y_hat_test_svr = testpredictSVR*(_maxtest - _mintest) + _mintest\n",
    "\n",
    "    RMSE_test_svr = (mean_squared_error(orig_y_eval_test, orig_y_hat_test_svr))**0.5\n",
    "    \n",
    "\n",
    "    print(f'RMSE: {RMSE_test_svr}')\n",
    "    print('------'*20)\n",
    "    return RMSE_test_svr,\n",
    "\n",
    "\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,)) # Maximise the fitness function value\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# Possible parameter values\n",
    "lag_option = [3, 6, 12, 24]\n",
    "norm = ['minmax', 'standard']\n",
    "cat = ['numeric', '1ofN', 'binary']\n",
    "hour = [True, False]\n",
    "month = [True, False]\n",
    "list_kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "lower_C, upper_C = 0.1, 50\n",
    "lower_epsilon, upper_epsilon = 0.001,1 \n",
    "\n",
    "N_CYCLES = 1\n",
    "toolbox.register(\"attr_lag\", random.choice, lag_option)\n",
    "toolbox.register(\"attr_normalization\", random.choice, norm)\n",
    "toolbox.register(\"attr_category\", random.choice, cat)\n",
    "toolbox.register(\"attr_hour\", random.choice, hour)\n",
    "toolbox.register(\"attr_month\", random.choice, month)\n",
    "toolbox.register(\"attr_kernel\", random.choice, list_kernel)\n",
    "toolbox.register(\"attr_C\", random.uniform, lower_C, upper_C)\n",
    "toolbox.register(\"attr_epochs\", random.uniform, lower_epsilon, upper_epsilon)\n",
    "\n",
    "toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
    "                 (toolbox.attr_lag,toolbox.attr_normalization, toolbox.attr_category,\n",
    "                  toolbox.attr_hour,toolbox.attr_month,toolbox.attr_kernel,toolbox.attr_C, \n",
    "                  toolbox.attr_epochs), n=N_CYCLES)\n",
    "\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "\n",
    "toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "toolbox.register(\"mutate\",mutate)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=2)\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "\n",
    "population_size = 4\n",
    "crossover_probability = 0.75\n",
    "mutation_probability = 0.05\n",
    "number_of_generations = 50\n",
    "\n",
    "pop = toolbox.population(n=population_size)\n",
    "hof = tools.HallOfFame(3)\n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register(\"avg\", np.mean)\n",
    "stats.register(\"std\", np.std)\n",
    "stats.register(\"min\", np.min)\n",
    "stats.register(\"max\", np.max)\n",
    "pop, log = algorithms.eaSimple(pop, toolbox, cxpb=crossover_probability, stats = stats, \n",
    "                               mutpb = mutation_probability, ngen=number_of_generations, halloffame=hof, \n",
    "                               verbose=True) \n",
    "\n",
    "svr_best_parameters_1 = hof[0] # save the optimal set of parameters\n",
    "svr_best_parameters_2 = hof[1]\n",
    "svr_best_parameters_3 = hof[2]\n",
    "print(svr_best_parameters_1)\n",
    "print(svr_best_parameters_2)\n",
    "print(svr_best_parameters_3)\n",
    "\n",
    "gen = log.select(\"gen\")\n",
    "max_ = log.select(\"max\")\n",
    "avg = log.select(\"avg\")\n",
    "min_ = log.select(\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aec116",
   "metadata": {},
   "outputs": [],
   "source": [
    "evolution = pd.DataFrame({'Generation': gen,\n",
    "                         'Max RMSE': max_,\n",
    "                          'Average':avg,\n",
    "                         'Min RMSE': min_})\n",
    "\n",
    "plt.title('Parameter Optimisation')\n",
    "plt.plot(evolution['Generation'], evolution['Min AUROC'], 'b', color = 'C1',\n",
    "         label = 'Min')\n",
    "plt.plot(evolution['Generation'], evolution['Average'], 'b', color = 'C2',\n",
    "         label = 'Average')\n",
    "plt.plot(evolution['Generation'], evolution['Max RMSE'], 'b', color = 'C3',\n",
    "         label= 'Max')\n",
    "\n",
    "\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.ylabel('RMSE')\n",
    "plt.xlabel('Generation')\n",
    "plt.xticks([0,5,10,15,20, 25, 30, 35, 40 ,45, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1994ca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train,_maxtrain, _mintrain, _meantrain, _stdtrain = preparing_data(df_train_micetreated, features= final_feature_list, lag = 24, normalize = 'minmax', category = '1ofN', onlyHour = , onlyMonth = )\n",
    "X_test, Y_test,_maxtest, _mintest, _meantest, _stdtest = preparing_data(df_test_micetreated, features= final_feature_list, lag = 24, normalize = 'minmax', category = '1ofN', onlyHour = , onlyMonth = )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721ea27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = SVR(kernel = svr_best_parameters_1[0], C=svr_best_parameters_1[1], epsilon=svr_best_parameters_1[2])\n",
    "regressor.fit(X_train, Y_train)\n",
    "\n",
    "testpredictSVR = multistep_prediction(regressor, X_test, 24)\n",
    "\n",
    "orig_y_eval_test = Y_test*(_maxtest - _mintest) + _mintest\n",
    "orig_y_hat_test_svr = testpredictSVR*(_maxtest - _mintest) + _mintest\n",
    "\n",
    "RMSE_test_svr = (mean_squared_error(orig_y_eval_test, orig_y_hat_test_svr))**0.5\n",
    "mape_svr = MAPE(orig_y_eval_test, orig_y_hat_test_svr)\n",
    "\n",
    "print(f'RMSE: {RMSE_test_svr}')\n",
    "print(f'MAPE: {mape_svr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c19154",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_real_day = mask_classification(orig_y_eval_test_day)\n",
    "classification_forecasting_svr_day = mask_classification(orig_y_hat_test_svr_day)\n",
    "\n",
    "print(confusion_matrix(classification_real_day, classification_forecasting_svr_day))\n",
    "cm_svr_day = confusion_matrix(classification_real_day, classification_forecasting_svr_day)\n",
    "\n",
    "cmn_day = cm_svr_day.astype('float') / cm_svr_day.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cmn_day,annot=True)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
